# 爬取知乎回答

## Scrapy

### 安装

https://pypi.org/project/Scrapy/

```
pip install Scrapy
```

如果安装太慢，网速不行，可以用豆瓣的源，这样安装会更快

```
pip install scrapy -i https://pypi.doubanio.com/simple/
```

官网：https://scrapy.org

官网文档：https://docs.scrapy.org/en/latest/

### 基本概念

- [命令行工具(Command line tools)](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/commands.html)：学习用于管理Scrapy项目的命令行工具
- [Items](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/items.html)：定义爬取的数据
- [Spiders](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html)：编写爬取网站的规则
- [选择器(Selectors)](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/selectors.html)：使用XPath提取网页的数据
- [Scrapy终端(Scrapy shell)](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/shell.html)：在交互环境中测试提取数据的代码
- [Item Loaders](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/loaders.html)：使用爬取到的数据填充item
- [Item Pipeline](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/item-pipeline.html)：后处理(Post-process)，存储爬取的数据
- [Feed exports](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/feed-exports.html)：以不同格式输出爬取数据到不同的存储端
- [Link Extractors](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/link-extractors.html)：方便用于提取后续跟进链接的类。

### 内置服务

- [Logging](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/logging.html)：了解Scrapy提供的logging功能。
- [数据收集(Stats Collection)](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/stats.html)：收集爬虫运行数据
- [发送email](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/email.html)：当特定事件发生时发送邮件通知
- [Telnet终端(Telnet Console)](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/telnetconsole.html):使用内置的Python终端检查运行中的crawler(爬虫)
- [Web Service](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/webservice.html)：使用web service对您的爬虫进行监控和管理

### 入门教程

该教程来自官网，详情请戳：https://docs.scrapy.org/en/latest/intro/tutorial.html

1. 创建一个新的Scrapy项目
2. 编写[spider](https://docs.scrapy.org/en/latest/topics/spiders.html#topics-spiders)，爬虫并提取数据
3. 使用命令行导出抓取的数据
4. 更改spider，以递归的方式跟随链接
5. 使用spider参数