# 爬虫：用selenium 爬取知网文献基本信息

> **selenium**是浏览器自动化测试框架
>
> 官方文档：https://www.selenium.dev/selenium/docs/api/py/index.html
>
> 优点：**selenium** 不需要判断网页数据加载的方式，可以自动控制浏览器
>
> 缺点：它占用的资源会更多，爬取的效率也会降低，不过比我们手动操作还是快很多的
>

前几天有个小伙伴让我帮他写个代码，要求如下：
- 爬取知网文献
- 检索条件：学科类别勾选“社会科学一辑”所有“法学”类；
- 文献类型“期刊”，来源“cssci”，时间不限
- 主题词“地下空间”

我尝试了一下，电脑版搞不定（应该是我水平差），但是手机版，可以简单实现这个功能

![](http://cdn.zhaojingyi0126.com/cnki.gif)

## 明确目的

流程：
- 用`selenium` （浏览器自动化测试框架）打开浏览器
- 输入检索关键词`地下空间`
- 筛选文献，把期刊来源设置为`cssci`
- 筛选学科（这部分后面再补充）
- 读取文献总数量，加载所有页面
- 读取每篇文献的`标题`、 `作者`、 `摘要`、 `来源`、`引用`、`链接`
- 保存成Excel文件

![汇总成Excel](http://cdn.zhaojingyi0126.com/IMG/17569167-40954df521e5aae4.png)

### 准备工作

在开始写代码之前，要保证两点：

1、你有Python的软件，安装好`selenium`的库了

2、安装对应的浏览器驱动

 安装`selenium` 也很简单，在`附件—>命令提示符` 打开窗口，输入`pip install selenium `

关于安装对应的浏览器驱动，以 Chrome 浏览器，点击右上角`点点点`的那个符号，选择`帮助 - 关于 Google Chrome`

![](http://cdn.zhaojingyi0126.com/IMG/17569167-e128c33c2d7d18c1.png)

可以看到浏览器的版本号，然后我们去下载一个驱动

![版本号](http://cdn.zhaojingyi0126.com/IMG/17569167-626c9af272597567.png)

打开 https://npm.taobao.org/mirrors/chromedriver ，选择一个和你版本比较接近的安装文件

![](http://cdn.zhaojingyi0126.com/IMG/17569167-9f0814b373cf3898.png)

我是Windows系统，所以我下载`chromedriver_win32.zip`

![](http://cdn.zhaojingyi0126.com/IMG/17569167-18a021c8223f6d7b.png)

下载之后，把这个文件解压，里面只有一个`.exe`后缀的驱动文件。把它剪切到 Python 安装目录的 Scripts 文件夹里。 

![](http://cdn.zhaojingyi0126.com/IMG/17569167-4262a26aa4b9ce9b.png)

怎么找到 Python 的安装目录，你可以在`附件—>命令提示符` ，打开命令提示符，输入`where python`。比如我的安装目录，在C盘下面

![](http://cdn.zhaojingyi0126.com/IMG/17569167-eb459783e656b3d6.png)

## Selenium

### 打开浏览器

`selenium`是个很神奇的东西，它可以帮你模拟浏览器的操作

先把库都放进来
```python
from selenium import webdriver   # selenium用于打开浏览器
import  time  # 把关于时间的库加进来，这个是系统自带的
```
把浏览器打开
```python
browser = webdriver.Chrome()  # 打开谷歌浏览器
```

如果你不想用谷歌浏览器，其他浏览器打开方式如下

```python
# 谷歌浏览器
browser = webdriver.Chrome()

# Safari浏览器
browser = webdriver.Safari()

# 火狐浏览器
browser = webdriver.Firefox()

# IE浏览器
browser = webdriver.Ie()

# Edge浏览器
browser = webdriver.Edge()

# 欧朋浏览器
browser = webdriver.Opera()
```

打开知网，用**time.sleep**人为的暂停一会，速度太快了自己都看不清操作~

```python
browser.get('http://wap.cnki.net/touch/web/guide')
time.sleep(0.3)
```

### 定位元素

**selenium** 的操作方式，和**BeautifulSoup** 类似

- 元素定位（找到第一个符合条件的元素）
  - find_element_by_id()：通过id定位
  - find_element_by_name()：通过name定位
  - find_element_by_class_name()：通过class定位
  - find_element_by_tag_name()：通过tag定位
  - find_element_by_link_text()：通过link定位
  - find_element_by_partial_link_text()：通过部分link模糊匹配
  - find_element_by_xpath()：
  - find_element_by_css_selector()：

如果需要找到所有符合条件的元素，只需要把**element**改成**elements**。比如`find_element_by_id()`改为`find_elements_by_id()`

**selenium** 找到的元素（返回值）都是 **WebElement** 对象

- WebElement
  - WebElement.text：获取元素文本内容
  - WebElement.get_attribute('属性名')：获取元素属性值

### 控制浏览器

- click()：点击元素
- send_keys()：模拟按键输入

## 数据清洗

### 搜索

进入搜索，输入主题。可以根据**ID**搜索，也可以根据**class**搜索

```python
topic = "地下空间"
browser.find_element_by_id('btnSearch').click()
browser.find_element_by_id('keyword_ordinary').send_keys(topic)
browser.find_element_by_class_name('btn-search').click()
time.sleep(0.3)
```

![](http://cdn.zhaojingyi0126.com/IMG/17569167-e47f710581d1765f.png)


![点击搜索](http://cdn.zhaojingyi0126.com/IMG/17569167-a7c1daadf3b8f23b.png)

### 筛选文献

把期刊来源勾选为“cssci”

```python
browser.find_element_by_id("articletype_a").click()
time.sleep(0.3)
browser.find_element_by_css_selector("a[data-value=\"14\"]").click()
```
![](http://cdn.zhaojingyi0126.com/IMG/17569167-a7e46626c8e04191.png)

### 获取文献数量

```python
num = browser.find_element_by_class_name('search-number').text
num = int(num[:-1])
```

![](http://cdn.zhaojingyi0126.com/IMG/17569167-5e0f0bc732a50d8c.png)

### 加载所有页面

```python
for i in range(int(num/10)):
    browser.find_element_by_class_name('c-company__body-item-more').click()
    time.sleep(0.3)
```
![](http://cdn.zhaojingyi0126.com/IMG/17569167-1b871c1fc657fd2f.png)

测试的时候，可以先加载3页，看看效果

```python
for i in range(3):
    browser.find_element_by_class_name('c-company__body-item-more').click()
    time.sleep(0.3) 
```

### 获取文献信息

```python
title = browser.find_elements_by_class_name('c-company__body-title')
author = browser.find_elements_by_class_name('c-company__body-author')
link = browser.find_elements_by_class_name('c-company-top-link')
content = browser.find_elements_by_class_name('c-company__body-content')
company = browser.find_elements_by_class_name('color-green')
info = browser.find_elements_by_class_name('c-company__body-info')
```
![](http://cdn.zhaojingyi0126.com/IMG/17569167-5605717f0b60bef2.png)

## 保存数据

### 保存到Excel

```python
# 定义保存Excel的位置
workbook = xlwt.Workbook()  #定义workbook
sheet = workbook.add_sheet(topic)  #添加sheet
head = ['标题', '作者', '摘要', '来源', '引用', '链接']    #表头
for h in range(len(head)):
    sheet.write(0, h, head[h])    #把表头写到Excel里面去
i = 1  #定义Excel表格的行数，从第二行开始写入，第一行已经写了表头    
for n in range(len(title)): 
    sheet.write(i, 0, title[n].text)
    sheet.write(i, 1, author[n].text)
    sheet.write(i, 2, content[n].text)
    sheet.write(i, 3, company[n].text)
    sheet.write(i, 4, info[n].text)
    sheet.write(i, 5, link[n].get_attribute('href'))    
    i += 1
workbook.save('C:/Users/Administrator/Desktop/知网.xls')
```

## 关闭浏览器

一般程序最后，我们用**quit**。如果只是中途要关闭部分网页，可以用**close**

```python
browser.quit()
# 退出并关闭全部窗口
browser.close()
# 关闭当前窗口
```

## 完整代码

```python
# -*- coding: utf-8 -*-
"""
Created on Wed Nov 13 15:25:33 2019

@author: Yenny
"""

from selenium import webdriver
import  time
import xlwt

browser = webdriver.Chrome()
# 打开博客
browser.get('http://wap.cnki.net/touch/web/guide')
time.sleep(0.3)

# 进入搜索，输入主题
topic = "地下空间"
browser.find_element_by_id('btnSearch').click()
browser.find_element_by_id('keyword_ordinary').send_keys(topic)
browser.find_element_by_class_name('btn-search').click()
time.sleep(0.3)

# 筛选文献
browser.find_element_by_id("articletype_a").click()
time.sleep(0.3)
browser.find_element_by_css_selector("a[data-value=\"14\"]").click()

# 筛选学科
# browser.find_element_by_id("menu-toggle").click()
# browser.find_element_by_class_name('c-filter-title').click()

# 获取文献数量
num = browser.find_element_by_class_name('search-number').text
num = int(num[:-1])

# 加载所有页面
for i in range(int(num/10)):
    browser.find_element_by_class_name('c-company__body-item-more').click()
    time.sleep(0.3)

#  加载3页
# for i in range(3):
#     browser.find_element_by_class_name('c-company__body-item-more').click()
#     time.sleep(0.3)  
    
# 把网页拉到最下面，确保网页加载完成
# browser.find_element_by_class_name("c-footer__copyright").click()
# time.sleep(0.3)

# 获取文献信息
title = browser.find_elements_by_class_name('c-company__body-title')
author = browser.find_elements_by_class_name('c-company__body-author')
link = browser.find_elements_by_class_name('c-company-top-link')
content = browser.find_elements_by_class_name('c-company__body-content')
company = browser.find_elements_by_class_name('color-green')
info = browser.find_elements_by_class_name('c-company__body-info')

# 保存到Excel
# 定义保存Excel的位置
workbook = xlwt.Workbook()  #定义workbook
sheet = workbook.add_sheet(topic)  #添加sheet
head = ['标题', '作者', '摘要', '来源', '引用', '链接']    #表头
for h in range(len(head)):
    sheet.write(0, h, head[h])    #把表头写到Excel里面去
i = 1  #定义Excel表格的行数，从第二行开始写入，第一行已经写了表头    
for n in range(len(title)): 
    sheet.write(i, 0, title[n].text)
    sheet.write(i, 1, author[n].text)
    sheet.write(i, 2, content[n].text)
    sheet.write(i, 3, company[n].text)
    sheet.write(i, 4, info[n].text)
    sheet.write(i, 5, link[n].get_attribute('href'))    
    i += 1
workbook.save('知网文献汇总.xls')

# 关闭浏览器
browser.quit()
```