# 爬虫：用selenium 爬取知网文献基本信息

前几天有个小伙伴让我帮他写个代码，要求如下：
- 爬取知网文献
- 检索条件：学科类别勾选“社会科学一辑”所有“法学”类；
- 文献类型“期刊”，来源“cssci”，时间不限
- 主题词“地下空间”

我尝试了一下，电脑版搞不定（应该是我水平差），但是手机版，可以简单实现这个功能

## 功能介绍
流程：
- 用`selenium` （浏览器自动化测试框架）打开浏览器
- 输入检索关键词`地下空间`
- 筛选文献，把期刊来源设置为`cssci`
- 筛选学科（这部分后面再补充）
- 读取文献总数量，加载所有页面
- 读取每篇文献的`标题`、 `作者`、 `摘要`、 `来源`、`引用`、`链接`
- 保存成Excel文件

![汇总成Excel](4.assets/17569167-40954df521e5aae4.png)


## 准备工作
在开始写代码之前，要保证两点：
1、你有Python的软件，安装好selenium 的库了
2、安装对应的浏览器驱动

Python的安装你可以点这里 [Python程序的安装和运行](https://www.jianshu.com/p/18a2c375d93f)

 安装selenium 也很简单，在`附件—>命令提示符` 打开窗口，输入`pip install selenium `

关于安装对应的浏览器驱动，以 Chrome 浏览器，点击右上角`点点点`的那个符号，选择`帮助 - 关于 Google Chrome`

![](4.assets/17569167-e128c33c2d7d18c1.png)

可以看到浏览器的版本号，然后我们去下载一个驱动

![版本号](4.assets/17569167-626c9af272597567.png)

打开 https://npm.taobao.org/mirrors/chromedriver ，选择一个和你版本比较接近的安装文件
![](4.assets/17569167-9f0814b373cf3898.png)

我是Windows系统，所以我下载`chromedriver_win32.zip`

![](4.assets/17569167-18a021c8223f6d7b.png)

下载之后，把这个文件解压，里面只有一个`.exe`后缀的驱动文件。把它剪切到 Python 安装目录的 Scripts 文件夹里。 

![](4.assets/17569167-4262a26aa4b9ce9b.png)

怎么找到 Python 的安装目录，你可以在`附件—>命令提示符` ，打开命令提示符，输入`where python`。比如我的安装目录，在C盘下面

![](4.assets/17569167-eb459783e656b3d6.png)

## 开始干活
selenium是个很神奇的东西，它可以帮你模拟浏览器的操作

先把库都放进来
```python
from selenium import webdriver   # selenium用于打开浏览器
import  time  # 把关于时间的库加进来，这个是系统自带的
import xlwt  # 这个库是为了后面保存Excel
```
把浏览器打开，用time.sleep人为的暂停一会，速度太快了自己都看不清操作~
```python
browser = webdriver.Chrome()
# 打开博客
browser.get('http://wap.cnki.net/touch/web/guide')
time.sleep(0.3)
```

进入搜索，输入主题。可以根据ID搜索，也可以根据class搜索

```python
topic = "地下空间"
browser.find_element_by_id('btnSearch').click()
browser.find_element_by_id('keyword_ordinary').send_keys(topic)
browser.find_element_by_class_name('btn-search').click()
time.sleep(0.3)
```

![输入主题词](4.assets/17569167-a7c1daadf3b8f23b.png)


![点击搜索](4.assets/17569167-e47f710581d1765f.png)


筛选文献，把期刊来源勾选为“cssci”

```python
browser.find_element_by_id("articletype_a").click()
time.sleep(0.3)
browser.find_element_by_css_selector("a[data-value=\"14\"]").click()
```
![勾选期刊](4.assets/17569167-a7e46626c8e04191.png)

获取文献数量
```python
num = browser.find_element_by_class_name('search-number').text
num = int(num[:-1])
```

![获取文献数量](4.assets/17569167-5e0f0bc732a50d8c.png)

加载所有页面
```python
for i in range(int(num/10)):
    browser.find_element_by_class_name('c-company__body-item-more').click()
    time.sleep(0.3)
```
![加载所有页面](4.assets/17569167-1b871c1fc657fd2f.png)


获取文献信息
```python
title = browser.find_elements_by_class_name('c-company__body-title')
author = browser.find_elements_by_class_name('c-company__body-author')
link = browser.find_elements_by_class_name('c-company-top-link')
content = browser.find_elements_by_class_name('c-company__body-content')
company = browser.find_elements_by_class_name('color-green')
info = browser.find_elements_by_class_name('c-company__body-info')
```
![获取文献信息](4.assets/17569167-5605717f0b60bef2.png)


保存到Excel
```python
# 定义保存Excel的位置
workbook = xlwt.Workbook()  #定义workbook
sheet = workbook.add_sheet(topic)  #添加sheet
head = ['标题', '作者', '摘要', '来源', '引用', '链接']    #表头
for h in range(len(head)):
    sheet.write(0, h, head[h])    #把表头写到Excel里面去
i = 1  #定义Excel表格的行数，从第二行开始写入，第一行已经写了表头    
for n in range(len(title)): 
    sheet.write(i, 0, title[n].text)
    sheet.write(i, 1, author[n].text)
    sheet.write(i, 2, content[n].text)
    sheet.write(i, 3, company[n].text)
    sheet.write(i, 4, info[n].text)
    sheet.write(i, 5, link[n].get_attribute('href'))    
    i += 1
workbook.save('C:/Users/Administrator/Desktop/知网.xls')
```


## 完整代码
```python
# -*- coding: utf-8 -*-
"""
Created on Wed Nov 13 15:25:33 2019

@author: Yenny
"""

from selenium import webdriver
import  time
import xlwt

browser = webdriver.Chrome()
# 打开博客
browser.get('http://wap.cnki.net/touch/web/guide')
time.sleep(0.3)

# 进入搜索，输入主题
topic = "地下空间"
browser.find_element_by_id('btnSearch').click()
browser.find_element_by_id('keyword_ordinary').send_keys(topic)
browser.find_element_by_class_name('btn-search').click()
time.sleep(0.3)

# 筛选文献
browser.find_element_by_id("articletype_a").click()
time.sleep(0.3)
browser.find_element_by_css_selector("a[data-value=\"14\"]").click()

# 筛选学科
# browser.find_element_by_id("menu-toggle").click()
# browser.find_element_by_class_name('c-filter-title').click()

# 获取文献数量
num = browser.find_element_by_class_name('search-number').text
num = int(num[:-1])

# 加载所有页面
for i in range(int(num/10)):
    browser.find_element_by_class_name('c-company__body-item-more').click()
    time.sleep(0.3)


# 获取文献信息
title = browser.find_elements_by_class_name('c-company__body-title')
author = browser.find_elements_by_class_name('c-company__body-author')
link = browser.find_elements_by_class_name('c-company-top-link')
content = browser.find_elements_by_class_name('c-company__body-content')
company = browser.find_elements_by_class_name('color-green')
info = browser.find_elements_by_class_name('c-company__body-info')

# 保存到Excel
# 定义保存Excel的位置
workbook = xlwt.Workbook()  #定义workbook
sheet = workbook.add_sheet(topic)  #添加sheet
head = ['标题', '作者', '摘要', '来源', '引用', '链接']    #表头
for h in range(len(head)):
    sheet.write(0, h, head[h])    #把表头写到Excel里面去
i = 1  #定义Excel表格的行数，从第二行开始写入，第一行已经写了表头    
for n in range(len(title)): 
    sheet.write(i, 0, title[n].text)
    sheet.write(i, 1, author[n].text)
    sheet.write(i, 2, content[n].text)
    sheet.write(i, 3, company[n].text)
    sheet.write(i, 4, info[n].text)
    sheet.write(i, 5, link[n].get_attribute('href'))    
    i += 1
workbook.save('C:/Users/Administrator/Desktop/知网.xls')
```